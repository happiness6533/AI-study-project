## 텐서플로우

1. api

- 고수준 api: 케라스: 아래의 레이어 클래스를 캡슐화해 둠
	- 모델의 다양한 정보들
	- model.inputs
	- model.outputs
	- model.summary()
	- model.save() >> tf.keras.models.load_model()을 사용해서 저장된 파일을 인스턴스로 불러올 수 있다
	- model.save_weights()
	- model.load_weights()
	- model.get_weights()
	- model.set_weights()
- 저수준 api: 파이썬 래퍼
	- tf.nn... tf.math 등등: 레이어 클래스 내부를 정의할 떄 이걸 쓴다 이건 전부 c++로 코딩되어 있음
	- 직접 할거면 넘파이로 하자
- c++ 계층(gpu에서 c++계층의 계산을 실행하기 위해서 텐서플로우가 nvidia의 cuda 라이브러리 사용)

2. 그래프

- 그래프 자첼ㄹ 최적화해서 성능을 끌어올림
- 분산처리 할 경우 서로 다른 노드에서 서로 다른 그래프 부분을 수행할 수 있음
- 그래프는 이식이 가능해서 유연성이 보장됨
- 전체 그래프가 연결된 경우 자동미분을 가능하게 해준다

- 레이지 모드
	- 실행해도 그래프를 돌리지 않으면 결과는 아직 나오지 않음
	- 그러나 일단 그래프를 생성하고 실제로 실행하기 전 그래프 최적화기가 작동
	- 같은 연산의 반복을 피하기 위해 캐시에 저장하고 병렬처리를 활용하기
	- 때문에 실제 수행시의 속도는 더 빠르다
	- 출력시 바로바로 결과를 알 수 없어서 개발에 불편

- 즉시 실행 모드(텐서플로우의 기본 모드)
	- 연산이 정의된 지점에서 그래프를 실행하지 않아도 바로 결과를 돌려준다
	- .numpy()를 쓰면 내부 값만 추출도 가능
	- 그러나 최적화 작업이 수행되지 않기 때문에 속도가 더 느림 => 오토 그래프로 해결한다
	- 또한 각각의 그래프가 독립적이기 때문에 자동 미분이 불가능함 => 그래디언트 테이프로 컨텍스트 내부에서 손실을 계산하고 연산을 기록해서 자동 미분

- 오토그래프
	- @tf.function 데코레이터를 함수에 붙이면 자동 최적화를 수행해준다
	- 따라서 즉시 실행 모드임에도 어느정도의 속도 향상을 보장해 줌
	- 현재 tf2를 설치하면 기본적으로 즉시 실행 모드이므로,
	- 레이지 모드로 세팅을 바꾸지 않을거라면 오토 그래프를 사용해주는 것이 좋다

3. tf 생태계

- 텐서보드
	- model.fit(...args, callbacks=[tf.keras.callbacks.TensorBoard('./logs)])
	- 위와 같이 수행한 경우 fit의 결과를 지정한 폴더에 저장하고 텐서보드로 열어볼 수 있다
	- 텐서보드를 여는 명렁어는 tensorboard --logdir ./logs
- 텐서플로우 애드온: 아직 공식적으로 tf에 합류하기 이른 것들의 집합체임
- 텐서플로우 익스텐디드: 엔드투엔드 플랫폼으로 데이터 검증, 변환, 모델 훈련, 모델 분석, 모델 rest api 서비스까지 모두 관리 가능한 플랫폼
- 로컬보다 원격에 gpu가 있는 경우 10~100배정도 더 빠르다
- 독자적인 원격 시스템을 쓸거라면 원격 서버에 주피터 노트북을 설치해서 쓰자(젠킨스까지...?ㄷㄷㄷ)
- 구글 클라우드 ml을 쓰면 원격 실행에 매우 유리하군
- 분산처리를 돕는 api도 있다ㄷㄷ tf.distribute.Strategy api
- 텐서플로우 자바스크립트